{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32f86d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Environment Validation ----\n",
      "GPU available: False\n",
      "HF_TOKEN:  SET\n",
      "HF_USER:  SET\n",
      "SPACE_NAME:  SET\n",
      "WANDB_API_KEY:  SET\n",
      "Dependencies: All imported successfully\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "print(\"---- Environment Validation ----\")\n",
    "print(\"GPU available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU name:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "for var in [\"HF_TOKEN\", \"HF_USER\", \"SPACE_NAME\"]:\n",
    "    val = os.environ.get(var)\n",
    "    print(f\"{var}:\", \" SET\" if val else \"NOT SET\")\n",
    "\n",
    "wandb_key = os.environ.get(\"WANDB_API_KEY\")\n",
    "print(\"WANDB_API_KEY:\", \" SET\" if wandb_key else \"Not set\")\n",
    "\n",
    "try:\n",
    "    import wandb, gradio, huggingface_hub\n",
    "    print(\"Dependencies: All imported successfully\")\n",
    "except Exception as e:\n",
    "    print(\"Dependencies: Missing:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3d35467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paste your Hugging Face token when prompted (it will be hidden)\n",
      "Credentials stored in environment\n",
      "Credentials stored in environment\n"
     ]
    }
   ],
   "source": [
    "from getpass import getpass\n",
    "import os\n",
    "\n",
    "print(\"Paste your Hugging Face token when prompted (it will be hidden)\")\n",
    "hf_token = getpass(\"Hugging Face token: \")\n",
    "os.environ['HF_TOKEN'] = hf_token\n",
    "\n",
    "hf_user = input(\"Enter your Hugging Face username: \").strip()\n",
    "space_name = input(\"Enter Space name (e.g., 'tiny-imagenet-classifier'): \").strip()\n",
    "\n",
    "os.environ['HF_USER'] = hf_user\n",
    "os.environ['SPACE_NAME'] = space_name\n",
    "\n",
    "print(\"Credentials stored in environment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97b4346f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will use artifact: /tiny-imagenet-assignment/resnet18-tiny-imagenet:latest\n"
     ]
    }
   ],
   "source": [
    "wandb_entity = input(\"Enter your W&B entity/username: \").strip()\n",
    "wandb_project = input(\"Enter W&B project name: \").strip() or \"tiny-imagenet-assignment\"\n",
    "\n",
    "os.environ['WANDB_ENTITY'] = \"ir2023\"\n",
    "os.environ['WANDB_PROJECT'] = \"tiny-imagenet-assignment\"\n",
    "\n",
    "print(f\"Will use artifact: {wandb_entity}/{wandb_project}/resnet18-tiny-imagenet:latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca9d155b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "app.py created successfully\n"
     ]
    }
   ],
   "source": [
    "code = \"\"\"\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet18\n",
    "import gradio as gr\n",
    "import json\n",
    "\n",
    "MODEL_PATH = \"outputs/best_model.pth\"\n",
    "\n",
    "# Load class names\n",
    "def load_class_names():\n",
    "    if os.path.exists(\"class_names.json\"):\n",
    "        with open(\"class_names.json\", \"r\") as f:\n",
    "            return json.load(f)\n",
    "    return {f\"class_{i}\": f\"class_{i}\" for i in range(200)}\n",
    "\n",
    "CLASS_NAMES = load_class_names()\n",
    "\n",
    "# Download model from W&B if not present\n",
    "if not os.path.exists(MODEL_PATH):\n",
    "    try:\n",
    "        import wandb\n",
    "        wandb_api_key = os.environ.get(\"WANDB_API_KEY\")\n",
    "        if wandb_api_key:\n",
    "            print(\"Downloading model from W&B...\")\n",
    "            wandb.login(key=wandb_api_key)\n",
    "            api = wandb.Api()\n",
    "            artifact_path = os.environ.get(\"WANDB_ARTIFACT\", \n",
    "            \"ir2023/tiny-imagenet-assignment/resnet18-tiny-imagenet:latest\")\n",
    "            print(f\"Downloading: {artifact_path}\")\n",
    "            artifact = api.artifact(artifact_path)\n",
    "            artifact.download(root=\"outputs\")\n",
    "            print(\"Model downloaded from W&B\")\n",
    "        else:\n",
    "            print(\"WANDB_API_KEY not set in Space Secrets\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading model: {e}\")\n",
    "\n",
    "# Load model\n",
    "print(\"Loading model...\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = resnet18(pretrained=False)\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_features, 200)\n",
    "\n",
    "try:\n",
    "    checkpoint = torch.load(MODEL_PATH, map_location=device)\n",
    "    if 'model_state_dict' in checkpoint:\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    else:\n",
    "        model.load_state_dict(checkpoint)\n",
    "    print(\"Model loaded successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {e}\")\n",
    "    raise\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Image preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                       std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "def predict_image(img):\n",
    "    if img is None:\n",
    "        return {\"error\": \"No image provided\"}\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        img_tensor = transform(img).unsqueeze(0).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(img_tensor)\n",
    "            probs = torch.nn.functional.softmax(outputs, dim=1)\n",
    "            top5_probs, top5_idx = torch.topk(probs, 5)\n",
    "        \n",
    "        results = {}\n",
    "        for prob, idx in zip(top5_probs[0], top5_idx[0]):\n",
    "            class_idx = int(idx.item())\n",
    "            class_name = list(CLASS_NAMES.values())[class_idx]\n",
    "            class_id = list(CLASS_NAMES.keys())[class_idx]\n",
    "            results[f\"{class_name} ({class_id})\"] = float(prob.item())\n",
    "        \n",
    "        latency = (time.time() - start_time) * 1000.0\n",
    "        print(f\"Prediction time: {latency:.2f}ms\")\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Prediction failed: {str(e)}\"}\n",
    "\n",
    "# Create Gradio interface\n",
    "title = \"Tiny ImageNet Classifier\"\n",
    "description = '''\n",
    "Upload an image to classify it into one of 200 Tiny ImageNet classes.\n",
    "\n",
    "**Model Details:**\n",
    "- Architecture: ResNet-18\n",
    "- Dataset: Tiny ImageNet (200 classes)\n",
    "- Input Size: 224x224 RGB\n",
    "- Framework: PyTorch\n",
    "\n",
    "Model is automatically downloaded from W&B at startup.\n",
    "'''\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=predict_image,\n",
    "    inputs=gr.Image(type=\"pil\", label=\"Upload Image\"),\n",
    "    outputs=gr.Label(num_top_classes=5, label=\"Top 5 Predictions\"),\n",
    "    title=title,\n",
    "    description=description,\n",
    "    theme=\"default\",\n",
    "    allow_flagging=\"never\"\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    iface.launch(server_name=\"0.0.0.0\", server_port=7860)\n",
    "\"\"\"\n",
    "with open(\"app.py\", \"w\") as f:\n",
    "    f.write(code)\n",
    "print(\"app.py created successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bcc1a017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created requirements.txt\n"
     ]
    }
   ],
   "source": [
    "with open(\"requirements.txt\", \"w\") as f:\n",
    "    f.write(\"\"\"torch==2.0.1\n",
    "    torchvision==0.15.2\n",
    "    gradio==4.0.0\n",
    "    Pillow==10.0.0\n",
    "    wandb>=0.16.0\n",
    "    huggingface_hub\n",
    "    git-lfs\n",
    "    \"\"\")\n",
    "\n",
    "print(\"Created requirements.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4c9bfb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Space: rahulmirapala/tiny-imagenet-classifier\n",
      "Space created: https://huggingface.co/spaces/rahulmirapala/tiny-imagenet-classifier\n",
      "Space created: https://huggingface.co/spaces/rahulmirapala/tiny-imagenet-classifier\n",
      "Files uploaded successfully!\n",
      "\n",
      "Space URL: https://huggingface.co/spaces/rahulmirapala/tiny-imagenet-classifier\n",
      "Files uploaded successfully!\n",
      "\n",
      "Space URL: https://huggingface.co/spaces/rahulmirapala/tiny-imagenet-classifier\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from huggingface_hub import HfApi\n",
    "\n",
    "# Clean up and prepare directory\n",
    "hf_space_dir = Path('hf_space')\n",
    "if hf_space_dir.exists():\n",
    "    shutil.rmtree(hf_space_dir)\n",
    "hf_space_dir.mkdir()\n",
    "\n",
    "# Copy required files\n",
    "shutil.copy('app.py', hf_space_dir / 'app.py')\n",
    "shutil.copy('requirements.txt', hf_space_dir / 'requirements.txt')\n",
    "\n",
    "# Copy class_names.json if it exists\n",
    "if Path('class_names.json').exists():\n",
    "    shutil.copy('class_names.json', hf_space_dir / 'class_names.json')\n",
    "\n",
    "# Create and push to Hugging Face Space\n",
    "token = os.environ.get(\"HF_TOKEN\")\n",
    "user = os.environ.get(\"HF_USER\")\n",
    "space = os.environ.get(\"SPACE_NAME\")\n",
    "\n",
    "if not token or not user or not space:\n",
    "    raise ValueError(\"HF_TOKEN, HF_USER or SPACE_NAME not set!\")\n",
    "\n",
    "api = HfApi(token=token)\n",
    "repo_id = f\"{user}/{space}\"\n",
    "\n",
    "print(f\"Creating Space: {repo_id}\")\n",
    "\n",
    "try:\n",
    "    repo_url = api.create_repo(\n",
    "        repo_id=repo_id,\n",
    "        repo_type=\"space\",\n",
    "        space_sdk=\"gradio\",\n",
    "        exist_ok=True\n",
    "    )\n",
    "    print(f\"Space created: {repo_url}\")\n",
    "    \n",
    "    api.upload_folder(\n",
    "        folder_path=str(hf_space_dir),\n",
    "        repo_id=repo_id,\n",
    "        repo_type=\"space\",\n",
    "        commit_message=\"Initial commit: Tiny ImageNet Gradio app\"\n",
    "    )\n",
    "    \n",
    "    print(\"Files uploaded successfully!\")\n",
    "    print(f\"\\nSpace URL: {repo_url}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    raise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
